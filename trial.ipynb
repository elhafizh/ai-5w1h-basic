{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pertama, kita panggil terlebih dahulu pustaka-pustaka yang dibutuhkan dan data pembelajaran yang sudah kita persiapkan sebelumnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy import load, displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pemanggilan data pembelajaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ner_spacy_fmt_datasets.pickle', 'rb') as f:\n",
    "    ner_spacy_fmt_datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selanjutnya kita akan buat model dari “model kosong” atau “blank-model” dengan perintah berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolio/code/event-extraction/venv/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th.\n",
      "  proc.begin_training(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<thinc.neural.optimizers.Optimizer at 0x7f5831c75c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.blank(\"id\")\n",
    "\n",
    "nlp.add_pipe(nlp.create_pipe('ner'))\n",
    "\n",
    "nlp.begin_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kita ambil data-modul untuk NER dan menyisihkan yang lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kita proses atau ambil label tipe entitas dari data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in ner_spacy_fmt_datasets:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Untuk data train akan kita random terlebih dahulu baru kemudian kita masukkan ke iterasi training, pada contoh ini kita coba untuk latih model sebanyak 30 kali perulangan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 {'ner': 46313.4103863339}\n",
      "Losses at iteration 1 {'ner': 44726.05711008631}\n",
      "Losses at iteration 2 {'ner': 44688.753690799625}\n",
      "Losses at iteration 3 {'ner': 44609.0059457256}\n",
      "Losses at iteration 4 {'ner': 44404.945039788014}\n",
      "Losses at iteration 5 {'ner': 44353.42911557443}\n",
      "Losses at iteration 6 {'ner': 43728.91765047358}\n",
      "Losses at iteration 7 {'ner': 43858.77372805169}\n",
      "Losses at iteration 8 {'ner': 43789.24379751411}\n",
      "Losses at iteration 9 {'ner': 43434.64601052977}\n",
      "Losses at iteration 10 {'ner': 43372.82921985403}\n",
      "Losses at iteration 11 {'ner': 43306.30348470662}\n",
      "Losses at iteration 12 {'ner': 43309.700816553064}\n",
      "Losses at iteration 13 {'ner': 43317.673493076916}\n",
      "Losses at iteration 14 {'ner': 43432.562191384226}\n",
      "Losses at iteration 15 {'ner': 43086.468654191995}\n",
      "Losses at iteration 16 {'ner': 43155.663107672044}\n",
      "Losses at iteration 17 {'ner': 43164.73287854719}\n",
      "Losses at iteration 18 {'ner': 43117.04583458355}\n",
      "Losses at iteration 19 {'ner': 42849.37611311673}\n",
      "Losses at iteration 20 {'ner': 42851.59822115462}\n",
      "Losses at iteration 21 {'ner': 42777.11808297575}\n",
      "Losses at iteration 22 {'ner': 42636.91945405277}\n",
      "Losses at iteration 23 {'ner': 42868.23715784429}\n",
      "Losses at iteration 24 {'ner': 42653.56559502891}\n",
      "Losses at iteration 25 {'ner': 42372.12801347417}\n",
      "Losses at iteration 26 {'ner': 42613.18086896716}\n",
      "Losses at iteration 27 {'ner': 42630.60453038318}\n",
      "Losses at iteration 28 {'ner': 42773.7463764908}\n",
      "Losses at iteration 29 {'ner': 42445.92633524017}\n"
     ]
    }
   ],
   "source": [
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(30):\n",
    "\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(ner_spacy_fmt_datasets)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(ner_spacy_fmt_datasets, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "    \n",
    "    print(\"Losses at iteration {}\".format(iteration), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SELUBUNG, Pendeta, Yeremia Zanambani, Kabupaten Intan Jaya, Papua, Intan Jaya)\n",
      "Entities [('SELUBUNG', 'ORGANIZATION'), ('Pendeta', 'ORGANIZATION'), ('Yeremia Zanambani', 'PERSON'), ('Kabupaten Intan Jaya', 'LOCATION'), ('Papua', 'LOCATION'), ('Intan Jaya', 'LOCATION')]\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "doc = nlp(\"SELUBUNG yang menyelimuti kasus penembakan yang menewaskan Pendeta Yeremia Zanambani di Kabupaten Intan Jaya, Papua kian terkuak. Hasil investigasi Tim Gabungan Pencari Fakta (TGPF) kasus tersebut menyatakan bahwa penembakan di Intan Jaya diduga dilakukan oleh aparat keamanan.\")\n",
    "\n",
    "print(doc.ents)\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to nlp_id_checkpoint_2021_11_02\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path('nlp_id_checkpoint_2021_11_02')\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from nlp_id_checkpoint_2021_11_02\n"
     ]
    }
   ],
   "source": [
    "# load existing model \n",
    "output_dir = 'nlp_id_checkpoint_2021_11_02'\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp_updated = spacy.load(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Bali', 'LOCATION')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Kementerian Perhubungan tidak mewajibkan rapid test COVID-19 untuk perjalanan darat lintas daerah, kecuali untuk tujuan \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bali\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       ". Termasuk, dalam periode cuti bersama.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# contoh 1\n",
    "doc = nlp_updated(\"Kementerian Perhubungan tidak mewajibkan rapid test COVID-19 untuk perjalanan darat lintas daerah, kecuali untuk tujuan Bali. Termasuk, dalam periode cuti bersama.\" )\n",
    "\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Empat saksi', 'QUANTITY'), ('PT Waskita Karya (Persero) Tbk', 'ORGANIZATION'), ('KPK', 'ORGANIZATION'), ('Hugua', 'PERSON')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Empat saksi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " terkait korupsi proyek infrastruktur fiktif yang dikerjakan \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PT Waskita Karya (Persero) Tbk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " absen dari panggilan \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    KPK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " hari ini. Seorang di antaranya mantan Bupati Wakatobi, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hugua\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# contoh 2\n",
    "doc = nlp_updated(\"Empat saksi terkait korupsi proyek infrastruktur fiktif yang dikerjakan PT Waskita Karya (Persero) Tbk absen dari panggilan KPK hari ini. Seorang di antaranya mantan Bupati Wakatobi, Hugua.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from nlp_id_checkpoint_2021_11_02\n"
     ]
    }
   ],
   "source": [
    "# load existing model \n",
    "output_dir = 'nlp_id_checkpoint_2021_11_02'\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp_updated = spacy.load(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Gung Kayon', 'PERSON'), ('Joko Widodo', 'PERSON'), ('Jokowi', 'PERSON'), ('Gung Kayon', 'PERSON')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Satu hari sebelum saya bertemu dengan \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gung Kayon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", Presiden \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joko Widodo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " gembar-gembor ingin masyarakat untuk tinggalkan energi fosil dan mulai beralih ke energi terbarukan. Mungkin \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jokowi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " tak sadar, apa yang diucapkannya sudah dijalani dan dihayati oleh \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gung Kayon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " sejak puluhan tahun silam.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_updated(\"Satu hari sebelum saya bertemu dengan Gung Kayon, Presiden Joko Widodo gembar-gembor ingin masyarakat untuk tinggalkan energi fosil dan mulai beralih ke energi terbarukan. Mungkin Jokowi tak sadar, apa yang diucapkannya sudah dijalani dan dihayati oleh Gung Kayon sejak puluhan tahun silam.\" )\n",
    "\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d95b4fd280ccc62efbd9db1fb4e9f4ecc4b4ab9d5ab069e950104ff3b4e263c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
